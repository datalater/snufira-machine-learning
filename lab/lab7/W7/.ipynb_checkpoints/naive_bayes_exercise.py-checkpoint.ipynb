{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New Copy : All-in-One\n",
    "\n",
    "+ code from [naive_bayes.py](https://github.com/seokjunS/naive_bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LabelEncoder() \n",
      "==================================================\n",
      "  outlook  temp humidity    wind\n",
      "0   sunny  cool     high  strong\n",
      "[[ 0.79541735  0.20458265]]\n",
      "no\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/snu/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:79: RuntimeWarning: divide by zero encountered in log\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\" An implementation of Naive Bayes for multiple categorical features.\n",
    "\" Create at: 2017-09-17\n",
    "\" Author: seokjunS\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from copy import deepcopy\n",
    "from collections import defaultdict\n",
    "from sklearn import model_selection, naive_bayes, metrics, preprocessing\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NaiveBayes(object):\n",
    "  \"\"\"\n",
    "  \" Naive Bayes model\n",
    "  \" Traning model with 'fit' function, while predicting new instance with 'predict' function.\n",
    "  \" 'predict_proba' function returns probability for each target classes.\n",
    "  \"\"\"\n",
    "  def __init__(self, alpha = 0.0):\n",
    "    self.alpha = alpha\n",
    "\n",
    "    self.data_encoders_ = []\n",
    "    self.target_encoder_ = None\n",
    "\n",
    "    self.class_count_ = None\n",
    "    self.class_log_prior_ = []\n",
    "    self.feature_log_prob_ = []\n",
    "\n",
    "  def fit(self, data, target):\n",
    "    # copy data\n",
    "    data = deepcopy(data)\n",
    "    target = deepcopy(target)\n",
    "\n",
    "    # encode target class labels\n",
    "    encoded, enc = self.learn_encoding( target )\n",
    "    target = encoded\n",
    "    self.target_encoder_ = enc\n",
    "\n",
    "\n",
    "    # calculate prior of target classes by counting\n",
    "    class_counts = self.counting(target)\n",
    "    \n",
    "    \"\"\"\n",
    "    \" TODO: make log probability from class_counts\n",
    "    \"\"\"\n",
    "    # self.class_log_prior_ = ???\n",
    "    \n",
    "    self.class_log_prior_ = np.log([class_counts[0]/sum(class_counts),\n",
    "                                    class_counts[1]/sum(class_counts)])\n",
    "\n",
    "    # encode features and calculate likelihood (log probability) by counting\n",
    "    for colname in data:\n",
    "      encoded, enc = self.learn_encoding( data[colname] )\n",
    "      data[colname] = encoded\n",
    "      self.data_encoders_.append( enc )\n",
    "\n",
    "      # add alpha smoothing\n",
    "      prob = np.full((len(enc.classes_), len(self.class_log_prior_)), fill_value=self.alpha)\n",
    "      \n",
    "      \"\"\"\n",
    "      \" TODO: counting values for each features\n",
    "      \"       by filling prob counting table.\n",
    "      \"\"\"\n",
    "      # counting features\n",
    "      for i, v in enumerate(data[colname]):\n",
    "        t = target[i]\n",
    "        prob[v, t] += 1.0\n",
    "        # t = ???\n",
    "        # prob[v,t] += ???\n",
    "\n",
    "      # convert counts to probability\n",
    "      prob = prob / np.sum(prob, axis=0)\n",
    "\n",
    "      # set log probability\n",
    "      self.feature_log_prob_.append( np.log(prob) )\n",
    "\n",
    "\n",
    "  def predict_proba(self, data):\n",
    "    data = deepcopy(data)\n",
    "    res = np.zeros((data.shape[0], len(self.class_log_prior_)))\n",
    "    \n",
    "    # encode features\n",
    "    for i, colname in enumerate(data):\n",
    "      data[colname] = self.encoding( data[colname], self.data_encoders_[i] )\n",
    "    \n",
    "\n",
    "    # calculate unnormalized posterior probability\n",
    "    for di, row in data.iterrows():\n",
    "      prob = 0.0\n",
    "      \"\"\"\n",
    "      \" TODO: calculate unnormalized log posterior\n",
    "      \"\"\"\n",
    "\n",
    "      for i, fp in enumerate(self.feature_log_prob_): # fp: feature likelihood table\n",
    "        prob += fp[row[i]]\n",
    "      prob += self.class_log_prior_\n",
    "\n",
    "      # convert log probability to probability\n",
    "      res[di] = np.exp(prob)\n",
    "    \n",
    "    # return normalized posterior probability\n",
    "    return res / np.sum(res)\n",
    "\n",
    "\n",
    "  def predict(self, data):\n",
    "    # calculate probability for each class\n",
    "    pred = self.predict_proba(data)\n",
    "    \"\"\"\n",
    "    \" TODO: select index whose probability is maximum.\n",
    "    \"\"\"\n",
    "    # select index whose probability is maximum.\n",
    "    labels = np.argmax(pred)\n",
    "    \n",
    "    # convert index to target class label\n",
    "    return self.target_encoder_.inverse_transform(labels)\n",
    "\n",
    "\n",
    "  ### helpers\n",
    "  def learn_encoding(self, col):\n",
    "    enc = preprocessing.LabelEncoder()\n",
    "    encoded = enc.fit_transform( col )\n",
    "    return encoded, enc\n",
    "\n",
    "  def encoding(self, col, enc):\n",
    "    return enc.transform( col )\n",
    "\n",
    "  def counting(self, arr):\n",
    "    # counting all different values and return counts in numerical order of original values\n",
    "    cnts = defaultdict(int)\n",
    "\n",
    "    for v in arr:\n",
    "      cnts[v] += 1.0\n",
    "\n",
    "    return np.array([ v for k,v in sorted(cnts.items(), key=lambda x: x[0]) ])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "  ### define input data\n",
    "  # Load play tennis whose first row is data header\n",
    "  rawdata = pd.read_csv('play_tennis.csv')\n",
    "\n",
    "  data = rawdata.iloc[:,:-1]\n",
    "  target = rawdata.iloc[:,-1]\n",
    "\n",
    "  model = NaiveBayes(alpha=0.0)\n",
    "\n",
    "  model.fit(data, target)\n",
    "\n",
    "  test_data = np.array([['sunny', 'cool', 'high', 'strong']])\n",
    "\n",
    "  test_data = pd.DataFrame(test_data, columns=['outlook', 'temp', 'humidity', 'wind'])\n",
    "  print(test_data)\n",
    "  print(model.predict_proba(test_data))\n",
    "  print(model.predict(test_data))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
